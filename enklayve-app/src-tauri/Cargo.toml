[package]
name = "enklayve-app"
version = "0.1.0"
description = "A secure, private, and personal desktop app for using top LLM models"
authors = ["Enklayve Contributors"]
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[lib]
# The `_lib` suffix may seem redundant but it is necessary
# to make the lib name unique and wouldn't conflict with the bin name.
# This seems to be only an issue on Windows, see https://github.com/rust-lang/cargo/issues/8519
name = "enklayve_app_lib"
crate-type = ["staticlib", "cdylib", "rlib"]

[build-dependencies]
tauri-build = { version = "2", features = [] }

[dependencies]
tauri = { version = "2", features = [] }
tauri-plugin-opener = "2"
tauri-plugin-dialog = "2"
tauri-plugin-fs = "2"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["full"] }
anyhow = "1"
thiserror = "1"
chrono = "0.4"

# Database
rusqlite = { version = "0.32", features = ["bundled"] }

# Document processing
pdf-extract = "0.7"
docx-rs = "0.4"
lopdf = "0.32"
html2text = "0.12"
calamine = "0.26"

# OCR - Pure Rust implementation (no external dependencies!)
ocrs = "0.11"
rten = "0.22"
image = "0.25"
hayro = "0.4"  # Pure Rust PDF renderer for OCR

# HTTP client for downloads (web search removed - Enklayve is 100% local!)
reqwest = { version = "0.12", features = ["stream", "rustls-tls"], default-features = false }
sha2 = "0.10"
hex = "0.4"
# urlencoding = "2.1"  # Removed - was only used for web search
# scraper = "0.18"     # Removed - was only used for web search HTML parsing

# Chunking and text processing
unicode-segmentation = "1.12"
regex = "1.10"

# Async runtime
futures = "0.3"

# Serialization for embeddings
bincode = "1.3"

# Hardware detection
sysinfo = "0.31"

# Embeddings
fastembed = "4.1"

# Parallel processing
rayon = "1.10"
num_cpus = "1.16"

# Backup and restore
zip = { version = "2.2", default-features = false, features = ["deflate"] }

# Encryption
aes-gcm = "0.10"
argon2 = "0.5"
rand = "0.8"
zeroize = "1.7"
base64 = "0.22"

# Platform directories
dirs = "5.0"

# Platform-specific dependencies
[target.'cfg(target_os = "macos")'.dependencies]
# Biometric authentication
security-framework = "2.9"
# LLM inference with Metal GPU support for Apple Silicon
llama-cpp-2 = { version = "0.1", features = ["metal"] }

[target.'cfg(target_os = "windows")'.dependencies]
# Windows APIs
windows = { version = "0.52", features = [
    "Win32_Security_Credentials",
    "Win32_Graphics_Dxgi",
    "Win32_Graphics_Dxgi_Common",
    "Win32_Foundation",
    "Security_Credentials_UI",
    "Foundation",
] }
# LLM inference (GPU support auto-detected at runtime)
llama-cpp-2 = { version = "0.1" }

[target.'cfg(target_os = "linux")'.dependencies]
# LLM inference with optional CUDA support
llama-cpp-2 = { version = "0.1", default-features = true }
# Note: Linux biometric and secure storage uses command-line tools:
# - secret-tool (libsecret) for keyring storage
# - fprintd-verify for fingerprint authentication
# - howdy for facial recognition (optional)
# This approach is more compatible across Linux distributions

# GPU acceleration features
[features]
default = ["auto-gpu"]
# Auto-enable GPU based on platform
auto-gpu = []
# CUDA support for NVIDIA GPUs (Windows/Linux)
cuda = ["llama-cpp-2/cuda"]
# Metal support for Apple Silicon (macOS)
metal = ["llama-cpp-2/metal"]
# All GPU features
gpu = ["cuda", "metal"]

[profile.release]
opt-level = "z"
lto = true
codegen-units = 1
strip = true
panic = "abort"

